Stacked Generalization with an Explainable AI Base Learner
Overview
This project explores a novel machine learning framework that combines Stacked Generalization with an Explainable AI (XAI) base learner to enhance predictive performance and interpretability in critical healthcare settings. The work focuses on ICU mortality prediction using the MIMIC-III dataset and integrates transparent models such as Explainable Boosting Machines (EBM) with powerful meta learners like SVM and MLP.

1. Introduction

Healthcare requires models that are not only accurate but also interpretable. Traditional black-box AI systems often lack transparency, limiting trust and adoption in clinical environments.
This project bridges this gap by introducing XAI-driven stacked generalization, enabling:

High predictive performance

Transparent and interpretable decision-making

Actionable insights for clinicians

2. Explainable AI in Healthcare

Explainable AI (XAI) provides interpretability by showing how and why models make predictions.
In healthcare, this leads to:

Increased clinician trust

Better understanding of risk factors

More reliable decision support

Improved patient outcomes

3. Stacked Generalization Framework

Stacked generalization uses a multi-layer architecture:

Layer 1 – Base Learner

Explainable Boosting Machine (EBM)

Uses Generalized Additive Models (GAM)

Extracts feature importance and interpretable contributions

Makes transparent predictions on ICU patient data

Layer 2 – Meta Learners

Support Vector Machine (SVM)

Multi-Layer Perceptron (MLP)

Meta learners utilize the feature contributions generated by EBM to learn complex, non-linear patterns.

4. Project Innovation

The key innovation lies in using Explainable AI as a feature extractor within a stacking architecture.
Benefits include:

Enhanced interpretability over black-box baselines

Improved predictive accuracy for ICU mortality

Better understanding of patient-specific risk factors

Meaningful insights for critical care environments

5. Dataset Overview

The project uses a subsample of the MIMIC-III ICU database.

Dataset Details

1,177 ICU patients

49 clinical features (vitals, labs, etc.)

Binary target: In-hospital mortality

Class imbalance present

6. EBM Explanation Insights

EBM provides:

Feature importance rankings

Individual patient-level feature contribution analysis

Visual explanation of risks

Support for more transparent clinical decisions

7. Performance Results
Three-Way Split Pipeline

SVM meta learner shows clear performance improvement over EBM base model

Demonstrates effectiveness of stacked learning

Two-Way Split Pipeline

Larger training sets improve F1 scores

Both SVM and MLP outperform baseline EBM

Reinforces advantage of meta learners in stacked architecture

8. Model Benefits

This XAI-driven stacked approach provides:

Transparency – Clinicians understand predictions

Accuracy – Meta learners improve outcome prediction

Trustworthiness – Models are reliable and interpretable

Better Patient Care – Supports informed decision-making

